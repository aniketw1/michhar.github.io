



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="A tech piece on back-propagation">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.0.6">
    
    
      
        <title>Back-Propagation in Deep Learning Frameworks</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.451f80e5.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.22915126.css">
      
      
        
        
        <meta name="theme-color" content="#009688">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="teal" data-md-color-accent="">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#introduction" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="Micheleen's Blog" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                Micheleen's Blog
              </span>
              <span class="md-header-nav__topic">
                Back-Propagation in Deep Learning Frameworks
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href=".." title="Micheleen's Blog" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Micheleen's Blog
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      2018
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        2018
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../how-i-built-pytorch-gpu/" title="Building PyTorch with LibTorch From Source with CUDA Support" class="md-nav__link">
      Building PyTorch with LibTorch From Source with CUDA Support
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../convert-pytorch-onnx/" title="How to Convert a PyTorch Model to ONNX Format" class="md-nav__link">
      How to Convert a PyTorch Model to ONNX Format
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../convolutional-in-layers-and-sequences/" title="Convolutional Neural Networks in Four Deep Learning Frameworks by Example" class="md-nav__link">
      Convolutional Neural Networks in Four Deep Learning Frameworks by Example
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../deploy-with-azureml-cli-boldly/" title="Deploying a Machine Learning Model Easily with Azure ML CLI" class="md-nav__link">
      Deploying a Machine Learning Model Easily with Azure ML CLI
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      2017
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        2017
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../cntk-has-feelings-too/" title="The Cognitive Toolkit (CNTK) Understands How You Feel" class="md-nav__link">
      The Cognitive Toolkit (CNTK) Understands How You Feel
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../masks_to_polygons_and_back/" title="Shapely Shapes and OpenCV Visions" class="md-nav__link">
      Shapely Shapes and OpenCV Visions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../single-artifical-neuron-for-nonlinear-separable-data/" title="On using an Adaline Artificial Neuron for Classification" class="md-nav__link">
      On using an Adaline Artificial Neuron for Classification
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../my-new-static-site-generator-hobby/" title="Overlaying a Website ontop of a GitHub Repository" class="md-nav__link">
      Overlaying a Website ontop of a GitHub Repository
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../data-science-story-part1/" title="On Being a Data Scientist" class="md-nav__link">
      On Being a Data Scientist
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../two-cents-on-python-package-structure/" title="Wading In a Tide Pool of Choices, How to Write a Package in Python?" class="md-nav__link">
      Wading In a Tide Pool of Choices, How to Write a Package in Python?
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../ocrbot-gets-attached/" title="OCRBot Gets Attached" class="md-nav__link">
      OCRBot Gets Attached
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../jupyter-and-beaker-make-a-case/" title="The Notebook Superhero -- Is It Always a Contest?" class="md-nav__link">
      The Notebook Superhero -- Is It Always a Contest?
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../javascript-and-python-have-a-party/" title="Javascript and Python Meet through Magic and IPython" class="md-nav__link">
      Javascript and Python Meet through Magic and IPython
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../confusion-matrix-code-revealed/" title="A Simple, Presentable Confusion Matrix with K-means Data" class="md-nav__link">
      A Simple, Presentable Confusion Matrix with K-means Data
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../a-python-flask-webapp-gets-smart/" title="Creating a Smart Python Flask Web App using Azure Machine Learning" class="md-nav__link">
      Creating a Smart Python Flask Web App using Azure Machine Learning
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      2016
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        2016
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../ocrbot-makes-a-connection/" title="OCRBot Makes a Connection to the Cloud" class="md-nav__link">
      OCRBot Makes a Connection to the Cloud
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../how-to-bot-on-mac/" title="Building an OCR Chat Bot with the Microsoft Bot Framework on my Mac" class="md-nav__link">
      Building an OCR Chat Bot with the Microsoft Bot Framework on my Mac
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../teaching-notes-post/" title="Tips I have Learned by Being a Trainer for a Year" class="md-nav__link">
      Tips I have Learned by Being a Trainer for a Year
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../notebooks1-post/" title="Python for Data Science Goes Into the Wild" class="md-nav__link">
      Python for Data Science Goes Into the Wild
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" title="Introduction" class="md-nav__link">
    Introduction
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#numpy-for-comparison" title="NumPy for Comparison" class="md-nav__link">
    NumPy for Comparison
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-code" title="The Code" class="md-nav__link">
    The Code
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speed" title="Speed" class="md-nav__link">
    Speed
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" title="Conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" title="References" class="md-nav__link">
    References
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Back-Propagation in Deep Learning Frameworks</h1>
                
                <p><strong>tl;dr</strong>:  </p>
<p><strong>Posted:</strong>  2018-04-22</p>
<h2 id="introduction">Introduction</h2>
<p>A rather lengthy introduction and code sample for back-propagation is written in NumPy below to set the stage for all future work in deep learning frameworks.  Then, how several deep learning frameworks perform/think about back-propagation follows.</p>
<p>I've found, recently, that the Sequential class in Keras and PyTorch are very similar to the Layer or Layers APIs in CNTK and TensorFlow - perhaps Sequential is a little bit higher-level so it depends on how much customizability you want, as usual in these cases.  Below you will see examples of the the same CNN architecture in the four different frameworks along with their back-propagation code.</p>
<h3 id="numpy-for-comparison">NumPy for Comparison</h3>
<p>This will set the stage for working with deep learning frameworks such as TensorFlow and PyTorch.  NumPy is the currency of the data used in these frameworks.  It is good to have a solid grasp on backpropagation and for a deeper explanation see  <a href="">Wikipedia</a>.</p>
<p>To quote a <a href="https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/07/04/how-to-implement-the-backpropagation-using-python-and-numpy/">good article</a> that can say this better than me:</p>
<blockquote>
<p>"The goal of back-propagation training is to minimize the squared error. To do that, the gradient of the error function must be calculated. The gradient is a calculus derivative with a value like +1.23 or -0.33. The sign of the gradient tells you whether to increase or decrease the weights and biases in order to reduce error. The magnitude of the gradient is used, along with the learning rate, to determine how much to increase or decrease the weights and biases.  Using some very clever mathematics, you can compute the gradient."</p>
</blockquote>
<p>The Neural Net class uses the following to kick-off the back propagation calculation (taken from this <a href="https://github.com/leestott/IrisData/blob/master/nn_backprop.py">Code</a>).</p>
<p>Before anything a few variables were set up in the NeuralNetwork class.</p>
<div class="highlight"><pre><span></span><span class="c1"># Number of input, hidden and output nodes respectively</span>
<span class="bp">self</span><span class="o">.</span><span class="n">ni</span> <span class="o">=</span> <span class="n">numInput</span>
<span class="bp">self</span><span class="o">.</span><span class="n">nh</span> <span class="o">=</span> <span class="n">numHidden</span>
<span class="bp">self</span><span class="o">.</span><span class="n">no</span> <span class="o">=</span> <span class="n">numOutput</span>

<span class="c1"># The values on the nodes</span>
<span class="bp">self</span><span class="o">.</span><span class="n">iNodes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ni</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">hNodes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">oNodes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># The weight matrices</span>
<span class="bp">self</span><span class="o">.</span><span class="n">ihWeights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ni</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">hoWeights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># The bias matrices</span>
<span class="bp">self</span><span class="o">.</span><span class="n">hBiases</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">oBiases</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>

<p>Part of the training code to initialize the gradients and signals (like gradients without their input terms) and looks like the following:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainData</span><span class="p">,</span> <span class="n">maxEpochs</span><span class="p">,</span> <span class="n">learnRate</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="n">hoGrads</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># hidden-to-output weights gradients</span>
    <span class="n">obGrads</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># output node biases gradients</span>
    <span class="n">ihGrads</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ni</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># input-to-hidden weights gradients</span>
    <span class="n">hbGrads</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># hidden biases gradients</span>

    <span class="n">oSignals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># output signals: gradients w/o assoc. input terms</span>
    <span class="n">hSignals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># hidden signals: gradients w/o assoc. input terms</span>

    <span class="o">...</span>
</pre></div>

<blockquote>
<p>Pro tip:  "When working with neural networks, it's common, but not required, to work with the float32 rather than float64 data type" - Lee Stott</p>
</blockquote>
<p>Now, followed with these arrays which will hold the signals (remember these are gradients without their input terms mainly for convenience) (<code>oSignals</code> the one from output to hidden and <code>hSignals</code> the hidden to input layer).</p>
<div class="highlight"><pre><span></span><span class="n">oSignals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">hSignals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>

<p>The calculation of the gradients, or amount used for the weight updates, are the steps as follows:</p>
<ol>
<li>Compute output node signals (an intermediate value)</li>
<li>Compute hidden-to-output weight gradients using output signals</li>
<li>Compute output node bias gradients using output signals</li>
<li>Compute hidden node signals</li>
<li>Compute input-to-hidden weight gradients using hidden signals</li>
<li>Compute hidden node bias gradients using hidden signals</li>
</ol>
<p><img alt="Backprop calculation" src="/img/backprop/0617vsm_McCaffreyFig2s.jpg" /></p>
<div class="highlight"><pre><span></span><span class="c1"># In setting up the training we had two variables</span>
<span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ni</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Expected values (training labels)</span>
<span class="n">t_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># 1. compute output node signals (an intermediate value)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">):</span>
    <span class="n">derivative</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">oNodes</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">oNodes</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># softmax</span>
    <span class="n">oSignals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">derivative</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">oNodes</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_values</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>  <span class="c1"># E=(t-o)^2 do E&#39;=(o-t)</span>

<span class="c1"># 2. compute hidden-to-output weight gradients using output signals</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">):</span>
    <span class="n">hoGrads</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">oSignals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hNodes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

<span class="c1"># 3. compute output node bias gradients using output signals</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">):</span>
    <span class="n">obGrads</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">oSignals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span>  <span class="c1"># 1.0 dummy input can be dropped</span>

<span class="c1"># 4. compute hidden node signals</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">):</span>
    <span class="nb">sum</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">no</span><span class="p">):</span>
    <span class="nb">sum</span> <span class="o">+=</span> <span class="n">oSignals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hoWeights</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">]</span>
    <span class="n">derivative</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">hNodes</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">hNodes</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>  <span class="c1"># tanh activation</span>
    <span class="n">hSignals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">derivative</span> <span class="o">*</span> <span class="nb">sum</span>

<span class="c1"># 5 compute input-to-hidden weight gradients using hidden signals</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ni</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">):</span>
    <span class="n">ihGrads</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">hSignals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">iNodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="c1"># 6. compute hidden node bias gradients using hidden signals</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">):</span>
    <span class="n">hbGrads</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">hSignals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span>  <span class="c1"># 1.0 dummy input can be dropped</span>

<span class="c1"># update weights and biases using the gradients</span>

<span class="o">...</span>
</pre></div>

<p>Updating the weight matrix now with these gradients will be left up to the reader (or use that code sample link above).</p>
<h2 id="the-code">The Code</h2>
<h2 id="speed">Speed</h2>
<h2 id="conclusion">Conclusion</h2>
<h2 id="references">References</h2>
<ol>
<li></li>
</ol>
<p>Thanks for reading.</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/michhar" class="md-footer-social__link fa fa-github"></a>
    
      <a href="https://twitter.com/rheartpython" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://linkedin.com/in/micheleenharris" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.5e60981f.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
    
      
        <script>!function(e,a,t,n,o,c,i){e.GoogleAnalyticsObject=o,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,c=a.createElement(t),i=a.getElementsByTagName(t)[0],c.async=1,c.src="https://www.google-analytics.com/analytics.js",i.parentNode.insertBefore(c,i)}(window,document,"script",0,"ga"),ga("create","UA-86308542-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview");var links=document.getElementsByTagName("a");if(Array.prototype.map.call(links,function(e){e.host!=document.location.host&&e.addEventListener("click",function(){var a=e.getAttribute("data-md-action")||"follow";ga("send","event","outbound",a,e.href)})}),document.forms.search){var query=document.forms.search.query;query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}</script>
      
    
  </body>
</html>