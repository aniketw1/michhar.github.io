
<!DOCTYPE html>
<html>
<head>
  
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">

    <title>Lessons from YOLO v3 Implementations in PyTorch &mdash; A blog on data science in the world of software development</title>

    <link rel="shortcut icon" href="../img/favicon.ico">
    <link rel="stylesheet" href="../css/alabaster.css" type="text/css">
    <link rel="stylesheet" href="../css/alabaster-overrides.css" type="text/css">

    
      <link href="../extra_css/extra.css" rel="stylesheet">
    
      <link href="../extra_css/syntax.css" rel="stylesheet">
    

    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/0.0.1/prism.min.js"></script>
    
      <script src="../search/main.js"></script>
    

    
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-86308542-1', 'auto');
        ga('send', 'pageview');
      </script>
    

    <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">

    
  
</head>
<body>

  <div class="document">
    <div class="documentwrapper">
      <div class="bodywrapper">
        <div class="body" role="main">
          
            <h1 id="lessons-from-yolo-v3-implementations-in-pytorch">Lessons from YOLO v3 Implementations in PyTorch</h1>
<p><img alt="yolov3" src="https://pjreddie.com/media/image/Screen_Shot_2018-03-24_at_10.48.42_PM.png" /><br>
<a href="https://pjreddie.com/darknet/yolo/" target="_blank">Image source</a></p>
<p><strong>tl:dr</strong>:  YOLO (for "you only look once") v3 is a relatively recent (April 2018) architecture design for object detection.  PyTorch (recently merged with Caffe2 and production as of November 2018) is a very popular deep learning library with Python and C++ bindings for both training and inference that is known for having dynamic graphs.  This post is about what I learned expanding a PyTorch codebase that can train object detection models for any number of classes and on custom data (<em>We love you COCO, but we have our own interets, now.</em>).</p>
<p><strong>Posted:</strong>  2019-11-23</p>
<h2 id="quick-links">Quick Links</h2>
<ul>
<li><a href="https://arxiv.org/pdf/1804.02767.pdf" target="_blank">Original YOLO v3 paper</a></li>
<li><a href="https://github.com/ayooshkathuria/pytorch-yolo-v3" target="_blank">Original PyTorch codebase</a></li>
<li><a href="https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/" target="_blank">Ayoosh Kathuria's original blog post on implementing YOLO v3 in PyTorch</a></li>
<li><a href="https://github.com/michhar/pytorch-yolo-v3-custom" target="_blank">My fork and rewrite for custom data and fine-tuning, etc.</a></li>
</ul>
<h2 id="lessons">Lessons</h2>
<h3 id="transfer-learning">Transfer learning</h3>
<p>In transfer learning we begin with a base model which gives us the weight values to start our training.  Objects from the training set of the base model, upon which the base model was trained, gets us closer to a new learned network for objects in the real world.  So, instead of starting with random weights to begin our training we begin from a "smarter" set of values.</p>
<ul>
<li>One tidbit I learned was to skip making batch normalization (BN) layers trainable.</li>
</ul>
<p>I recently learned from <a href="https://medium.com/luminovo/a-refresher-on-batch-re-normalization-5e0a1e902960" target="_blank">A refresher on batch (re-)normalization</a> that:</p>
<p><em>"When the mini-batch mean (µB) and mini-batch standard deviation (σB) diverge from the mean and standard deviation over the entire training set too often, BatchNorm breaks."</em></p>
<p>And that there are perils in hyperparameter tuning in conjunction with retraining BN layers and a few extra steps required to fix this (with a technique call batch renormalization) - so for simplicity sake, I left out retraining on BN layers, but look at batch renormalization techniques in the post above for addressing the complex issue if you wish.</p>
<p>How to allow layers in a PyTorch model to be trainable (minus BNs).</p>
<pre>
<code class="language-python">
# Freeze layers according to user specification
stop_layer = layers_length - args.unfreeze # Freeze up until this layer
cntr = 0

for name, param in model.named_parameters():
    if cntr < stop_layer:
        param.requires_grad = False
    else:
        if 'batch_norm' not in name:
            print("Parameter has gradients tracked.")
            param.requires_grad = True
        else:
            param.requires_grad = False
    cntr+=1
    </code>
</pre>

<h3 id="finetuning">Finetuning</h3>
<ul>
<li>How much of network to "open up" or set as trainable (the parameters that is)? - it's recommended at times to open it more (likely all of the parameters in fine-tuning phase) if the object or objects are very different from any COCO classes, which is called domain adaptation (NB:  the <code>yolov3.weights</code> base model from darknet is trained on COCO dataset).  So, for instance, if the base model has never seen a caterpillar before (not in COCO), you may want to let more layers be trainable.</li>
</ul>
<p>How to allow even more layers in the PyTorch model to be trainable (could set <code>stop_layer</code> to 0 to train whole network):</p>
<pre>
<code class="language-python">
# "unfreeze" refers to the last number of layers to tune (allow gradients to be tracked - backprop)
stop_layer = layers_length - (args.unfreeze * 2) # Freeze up to this layer (open up more than first phase)

"""...[same as above section]"""
    </code>
</pre>

<ul>
<li>Another learning is that if the network is not converging, try opening up all of the layers during fine-tuning.</li>
</ul>
<h3 id="data-augmentation">Data augmentation</h3>
<p>Some of these I learned the hard way, others from the wonderful PyTorch forums and StackOverflow.</p>
<ul>
<li>Be careful of conversions from a 0-255 to a 0-1 range as you don't want to do that more than once in code.</li>
<li>Keep this simple at first with only the resize and normalization.  Try with several types of augmentation next, increasing in complexity with each experiment.</li>
</ul>
<p>Start with just resize and standard pixel intensity normalize.  (NB:  the transforms operate on PIL images, then convert to <code>numpy</code> 3D array and finally to <code>torch.tensor()</code>)</p>
<pre>
<code class="language-python">
custom_transforms = Sequence([YoloResizeTransform(inp_dim), Normalize()])
    </code>
</pre>

<p>Then get fancier with hue, saturation and brightness shifts, for example (look in <code>cfg</code> for the amounts if following along in <a href="https://github.com/michhar/pytorch-yolo-v3-custom" target="_blank">code</a>).</p>
<pre>
<code class="language-python">
custom_transforms = Sequence([RandomHSV(hue=hue, saturation=saturation, brightness=exposure), 
    YoloResizeTransform(inp_dim), Normalize()])
    </code>
</pre>

<p>Where Normalize is a pixel intensity normalization (here, not to unit norm because we do that elsewhere) (based on <a href="https://stackoverflow.com/questions/7422204/intensity-normalization-of-image-using-pythonpil-speed-issues" target="_blank">accepted answer on StackOverflow</a>):</p>
<pre>
<code class="language-python">
class Normalize(object):
    """Pixel-intensity normalize the input numpy image"""

    def __init__(self):
        self.channels = 3

    def __call__(self, img, bboxes):
        """
        Args:
            img : numpy array
                Image to be scaled.
        Returns:
            img : numpy array
                normalize image.
        """
        arr = img.astype('float')
        # Do not touch the alpha channel
        for i in range(self.channels):
            minval = arr[...,i].min()
            maxval = arr[...,i].max()
            if minval != maxval:
                arr[...,i] -= minval
                # Don't divide by 255 because already doing elsewhere
                arr[...,i] *= ((maxval-minval))
        return arr, bboxes
    </code>
</pre>

<ul>
<li>A great option for augmentation is to double or triple the size of a dataset with a library like <code>imgaug</code> which can handle bounding boxes and polygons now.</li>
</ul>
<h3 id="learning-rate-schedulers">Learning rate schedulers</h3>
<p>There are some great learning rate schedulers to decrease learning rate with training on a schedule or automatically in the <a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate"><code>torch.optim.lr_scheduler</code></a> and set of methods therein.</p>
<p>The following is more of an implementation detail, but nonetheless, found it helpful to not make the mistake.</p>
<ul>
<li>Place the learning rate scheduler at the level of the epoch update, <strong>not</strong> the inner loop over batches of data (where the optimizer is).</li>
</ul>
<h2 id="yolo-glossary">YOLO Glossary</h2>
<ul>
<li>YOLOv3:  You Only Look Once v3.  Improvments over v1, v2 and YOLO9000 which include <a href="https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b">Ref</a>:<ul>
<li>Predicts more bounding boxes per image (hence a bit slower than previous YOLO architectures)</li>
<li>Detections at 3 scales</li>
<li>Addressed issue of detecting small objects</li>
<li>New loss function (cross-entropy replaces squared error terms)</li>
<li>Can perform multi-label classification (no more mutually exclusive labels)</li>
<li>Performance on par with other architectures (a bit faster than SSD, even, in many cases)</li>
</ul>
</li>
<li>Tiny-YOLOv3:  A reduced network architecture for smaller models designed for mobile, IoT and edge device scenarios</li>
<li>Anchors:  There are 5 anchors per box.  The anchor boxes are designed for a specific dataset using K-means clustering, i.e., a custom dataset must use K-means clustering to generate anchor boxes.  It does not assume the aspect ratios or shapes of the boxes. <a href="https://medium.com/@vivek.yadav/part-1-generating-anchor-boxes-for-yolo-like-network-for-vehicle-detection-using-kitti-dataset-b2fe033e5807">Ref</a></li>
<li>Loss:  using <code>nn.MSELoss</code> (for loss confidence) or mean squared error</li>
<li>IOU:  intersection over union between predicted bounding boxes and ground truth boxes</li>
</ul>
<h2 id="references">References</h2>
<ol>
<li><a href="https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607" target="_blank">37 Reasons why your Neural Network is not working</a></li>
<li><a href="https://github.com/aleju/imgaug" target="_blank"><code>imgaug</code> augmentation Python library</a></li>
<li><a href="https://machinethink.net/blog/object-detection-with-yolo/" target="_blank">Real-time object detection with YOLO</a></li>
<li>
<p><a href="https://medium.com/luminovo/a-refresher-on-batch-re-normalization-5e0a1e902960" target="_blank">A refresher on batch (re-)normalization</a>
<div id="disqus_thread"></div>
<script>
    /**</p>
<ul>
<li>RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.</li>
<li>LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: <a href="https://disqus.com/admin/universalcode/#configuration-variables">https://disqus.com/admin/universalcode/#configuration-variables</a>
 */</li>
</ul>
<p>var disqus_config = function () {
    this.page.url = '<a href="https://michhar.github.io/bilstm-crf-this-is-mind-bending/">https://michhar.github.io/bilstm-crf-this-is-mind-bending/</a>';  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = 'happycat1'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};</p>
<p>(function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');</p>
<pre><code>s.src = 'https://michhar.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
</code></pre>
<p>})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></p>
</li>
</ol>
            
          
        </div>
      </div>
    </div>
    <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
      <div class="sphinxsidebarwrapper">
        
          
            
  <p class="logo">
    <a href="..">
      <img class="logo" src="../img/RheartPython.jpg" title="A blog on data science in the world of software development">
    </a>
  </p>
  



          
            



<nav>
  <ul>
  
    
      <li>
        <a href="/">Home</a>
      </li>
      
    
    <br/>
  
    
      <li>
        2019
        <ul>
  
    
      <li>
        <a href="/learning-from-learning-yolov3/">Lessons from YOLO v3 Implementations in PyTorch</a>
      </li>
      
        <ul>
    
      <li><a href="#lessons-from-yolo-v3-implementations-in-pytorch">Lessons from YOLO v3 Implementations in PyTorch</a></li>
      <ul>
    
      <li><a href="#quick-links">Quick Links</a></li>
      <ul>
    
  </ul>
    
      <li><a href="#lessons">Lessons</a></li>
      <ul>
    
      <li><a href="#transfer-learning">Transfer learning</a></li>
      <ul>
    
  </ul>
    
      <li><a href="#finetuning">Finetuning</a></li>
      <ul>
    
  </ul>
    
      <li><a href="#data-augmentation">Data augmentation</a></li>
      <ul>
    
  </ul>
    
      <li><a href="#learning-rate-schedulers">Learning rate schedulers</a></li>
      <ul>
    
  </ul>
    
  </ul>
    
      <li><a href="#yolo-glossary">YOLO Glossary</a></li>
      <ul>
    
  </ul>
    
      <li><a href="#references">References</a></li>
      <ul>
    
  </ul>
    
  </ul>
    
  </ul>
      
    
    <br/>
  
    
      <li>
        <a href="/bilstm-crf-this-is-mind-bending/">Named Entity Recognition using a Bi-LSTM with the Conditional Random Field Algorithm</a>
      </li>
      
    
    <br/>
  
  </ul>
      </li>
    
    <br/>
  
    
      <li>
        2018
        <ul>
  
    
      <li>
        <a href="/how-i-built-pytorch-gpu/">Building PyTorch with LibTorch From Source with CUDA Support</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/convert-pytorch-onnx/">How to Convert a PyTorch Model to ONNX Format</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/convolutional-in-layers-and-sequences/">Convolutional Neural Networks in Four Deep Learning Frameworks by Example</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/deploy-with-azureml-cli-boldly/">Deploying a Machine Learning Model Easily with Azure ML CLI</a>
      </li>
      
    
    <br/>
  
  </ul>
      </li>
    
    <br/>
  
    
      <li>
        Archive
        <ul>
  
    
      <li>
        2017
        <ul>
  
    
      <li>
        <a href="/cntk-has-feelings-too/">The Cognitive Toolkit (CNTK) Understands How You Feel</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/masks_to_polygons_and_back/">Shapely Shapes and OpenCV Visions</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/single-artifical-neuron-for-nonlinear-separable-data/">On using an Adaline Artificial Neuron for Classification</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/my-new-static-site-generator-hobby/">Overlaying a Website ontop of a GitHub Repository</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/data-science-story-part1/">On Being a Data Scientist</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/two-cents-on-python-package-structure/">Wading In a Tide Pool of Choices, How to Write a Package in Python?</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/ocrbot-gets-attached/">OCRBot Gets Attached</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/jupyter-and-beaker-make-a-case/">The Notebook Superhero -- Is It Always a Contest?</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/javascript-and-python-have-a-party/">Javascript and Python Meet through Magic and IPython</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/confusion-matrix-code-revealed/">A Simple, Presentable Confusion Matrix with K-means Data</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/a-python-flask-webapp-gets-smart/">Creating a Smart Python Flask Web App using Azure Machine Learning</a>
      </li>
      
    
    <br/>
  
  </ul>
      </li>
    
    <br/>
  
    
      <li>
        2016
        <ul>
  
    
      <li>
        <a href="/ocrbot-makes-a-connection/">OCRBot Makes a Connection to the Cloud</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/how-to-bot-on-mac/">Building an OCR Chat Bot with the Microsoft Bot Framework on my Mac</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/teaching-notes-post/">Tips I have Learned by Being a Trainer for a Year</a>
      </li>
      
    
    <br/>
  
    
      <li>
        <a href="/notebooks1-post/">Python for Data Science Goes Into the Wild</a>
      </li>
      
    
    <br/>
  
  </ul>
      </li>
    
    <br/>
  
  </ul>
      </li>
    
    <br/>
  
  </ul>

  
  
  <br/>
  <br/>

  <a href="https://github.com/michhar/michhar.github.io/" target="_blank" style="border-bottom: 0">
    <i class="fab fa-github fa-2x"></i> Check out this repo on GitHub
  </a>
</nav>
          
        
      </div>
    </div>
    <div class="clearer"></div>
  </div>

  
    <div class="footer">
      
      
        
        Powered by <a href="http://www.mkdocs.org">mkdocs 1.0.4</a>
        &amp; <a href="https://github.com/iamale/mkdocs-alabaster">mkdocs-alabaster</a>
      
    </div>
  

  <!--
  MkDocs version      : 1.0.4
  Docs Build Date UTC : 2019-11-23 22:07:04
  -->
</body>
</html>