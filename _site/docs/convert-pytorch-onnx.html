<p><img src="img/pytorch_loves_onnx.png" alt="" /></p>

<p>Posted:  2018-09-27</p>

<p>It might seem tricky or intimidating to convert model formats, but ONNX makes it easier.  However, we must get our PyTorch model into the ONNX format.  This involves both the weights and network architecture defined by a PyToch model class (inheriting from <code class="highlighter-rouge">nn.Module</code>).</p>

<p>I donâ€™t write out the model classes, however, I wanted to share the steps and code from the point of having the class definition and some weights (either in memory or from a model path file).  One could also do this with the pre-trained models from the torchvision library.</p>

<h2 id="the-general-steps">The General Steps</h2>

<ol>
  <li>Define the model class (if using a custom model)</li>
  <li>Train the model and/or load the weights, usually a <code class="highlighter-rouge">.pth</code> or <code class="highlighter-rouge">.pt</code> file by convention, to something usually called the <code class="highlighter-rouge">state_dict</code> - note, we are <em>only</em> loading the weights from a file.  A pre-trained model such as is found in <code class="highlighter-rouge">torchvision.models</code> may also be used with the provided weights (using <code class="highlighter-rouge">pretrained=True</code> - see below).</li>
  <li>Create a properly shaped input vector (can be some sample data - the important part is the shape)</li>
  <li>(Optional) Give the input and output layers names (to later reference back)</li>
  <li>Export to ONNX format with the PyTorch ONNX exporter</li>
</ol>

<h2 id="prerequisites">Prerequisites</h2>

<ol>
  <li>PyTorch and torchvision installed</li>
  <li>A PyTorch model class and model weights</li>
</ol>

<h2 id="using-a-custom-model-class-and-weights-file">Using a Custom Model Class and Weights File</h2>

<p>The Python looks something like:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>

<span class="c1"># A model class instance (class not shown)
</span><span class="n">model</span> <span class="o">=</span> <span class="n">MyModelClass</span><span class="p">()</span>

<span class="c1"># Load the weights from a file (.pth usually)
</span><span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span>

<span class="c1"># Load the weights now into a model net architecture defined by our class
</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>

<span class="c1"># Create the right input shape (e.g. for an image)
</span><span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">sample_batch_size</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="s">"onnx_model_name.onnx"</span><span class="p">)</span>
</code></pre></div></div>

<p>The state dictionary, or <code class="highlighter-rouge">state_dict</code>, is a Python dict containing parameter values and persistent buffers.  (<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.load_state_dict">Docs</a>)</p>

<blockquote>
  <p>Note:  The preferred way of saving the weights is with <code class="highlighter-rouge">torch.save(the_model.state_dict(), &lt;name_here.pth&gt;)</code>. (<a href="https://pytorch.org/docs/stable/notes/serialization.html#recommended-approach-for-saving-a-model">Docs</a>)</p>
</blockquote>

<h2 id="a-pre-trained-model-from-torchvision">A Pre-Trained Model from torchvision</h2>

<p>If using the <code class="highlighter-rouge">torchvision.models</code> pretrained vision models all you need to do is, e.g., for AlexNet:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="n">models</span>

<span class="c1"># Use an existing model from Torchvision, note it 
# will download this if not already on your computer (might take time)
</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">alexnet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Create some sample input in the shape this model expects
</span><span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>

<span class="c1"># It's optional to label the input and output layers
</span><span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span> <span class="s">"actual_input_1"</span> <span class="p">]</span> <span class="o">+</span> <span class="p">[</span> <span class="s">"learned_</span><span class="si">%</span><span class="s">d"</span> <span class="o">%</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span> <span class="p">]</span>
<span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span> <span class="s">"output1"</span> <span class="p">]</span>

<span class="c1"># Use the exporter from torch to convert to onnx 
# model (that has the weights and net arch)
</span><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="s">"alexnet.onnx"</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">input_names</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">output_names</span><span class="p">)</span>
</code></pre></div></div>

<blockquote>
  <p>Note, the pretrained model weights that comes with <code class="highlighter-rouge">torchvision.models</code> went into a home folder <code class="highlighter-rouge">~/.torch/models</code> in case you go looking for it later.</p>
</blockquote>

<h2 id="summary">Summary</h2>

<p>Here, I showed how to take a pre-trained PyTorch model (a weights object and network class object) and convert it to ONNX format (that contains the weights and net structure).</p>

<p>As of now, we can not import an ONNX model for use in PyTorch.  There are other projects that are working on this as well as is shown in <a href="https://github.com/ysh329/deep-learning-model-convertor" target="_blank">this list</a>.</p>

<h2 id="more-references">More References</h2>

<ol>
  <li><a href="https://pytorch.org/docs/stable/onnx.html#module-torch.onnx" target="_blank">Example: End-to-end AlexNet from PyTorch to Caffe2</a></li>
  <li><a href="https://github.com/onnx/onnx" target="_blank">ONNX GitHub</a></li>
  <li><a href="https://pytorch.org" target="_blank">PyTorch.org</a></li>
  <li><a href="https://github.com/michhar/pytorch-yolo-v3-custom/blob/master/convert2onnx.py" target="_blank">For a more complicated example, see this conversion</a></li>
</ol>

<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    
    var disqus_config = function () {
        this.page.url = 'https://michhar.github.io/convolutional-in-layers-and-sequences/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'happycat1'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        
        s.src = 'https://michhar.disqus.com/embed.js';
        
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
