<p><strong>Posted:</strong>  2018-03-11</p>

<p><strong>UPDATE 2018-09-27</strong>:  Please refer to this excellent new documentation on the newly released AML CLI <a href="https://docs.microsoft.com/en-us/azure/machine-learning/desktop-workbench/model-management-cli-reference">Doc</a>.</p>

<h2 id="context">Context</h2>

<p>I was looking for an easy way to deploy a machine learning model I’d trained for classification, built with Microsoft Cogntive Toolkit (CNTK), a deep learning framework.  I wanted still to test locally with the Python code I wrote, then dockerize and test my image locally, as well.  If the local image ran, I wished to, then, deploy the tested, dockerized service to a cluster for a realtime scoring endpoint (with just a handful of commands if possible - and, indeed, it was).</p>

<p>This post is mainly about the commands to use for deploying with the new, in Preview, Azure ML CLI, however for example scoring files and schema with CNTK, see the <a href="#references">References</a> below.</p>

<h2 id="prerequisites">Prerequisites</h2>

<ol>
  <li>AzureML CLI (Install Using the CLI in this <a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/deployment-setup-configuration#using-the-cli">Doc</a>)</li>
  <li>Docker installed (for local service testing) - <a href="https://docs.docker.com/get-started/">Ref</a></li>
  <li>A scoring script (see <a href="#references">References</a> for examples)</li>
  <li>Any other necessary files like labels or necessary <code class="highlighter-rouge">pip</code> installs in a <code class="highlighter-rouge">requirements.txt</code></li>
</ol>

<p>Note:  The following was all done in Jupyter on a Linux Ubuntu Data Science Virutal Machine (<a href="https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/dsvm-ubuntu-intro">Doc</a>)</p>

<h2 id="overview">Overview</h2>

<p>Save for writing the actual code and installing the prerequisites, all can be done with the CLI, even running a quick service test call.</p>

<p>The general story goes as follows.  There is a local testing grounds and a remote cluster deployment in the overview outline.</p>

<h3 id="to-begin">To Begin</h3>

<ol>
  <li>Write a scoring script that has <code class="highlighter-rouge">run</code> and <code class="highlighter-rouge">init</code> methods, with a <code class="highlighter-rouge">main</code> method to make the service payload schema (an example <a href="https://github.com/Azure/MachineLearningSamples-ImageClassificationUsingCntk/blob/master/scripts/deploymain.py">Ref</a>).  The scoring script is packaged up for use later, but has a dual purpose of generating a schema for the service.  Run this script to generate the schema.  Package and deploy this script to make prediction service.</li>
  <li>Write a conda dependencies and/or <code class="highlighter-rouge">pip</code> install requirements file (this will have the reference to the CNTK wheel to install cntk into the docker image - we’ll talk about in a second)</li>
  <li>Register three Environment Providers (for the cluster deployment)</li>
  <li>Create a Model Management Account in Azure</li>
</ol>

<ul>
  <li>There’s an option to use one master, do-it-all, command or run separate commands as done here.  The separate commands perform the following.</li>
</ul>

<h3 id="for-a-local-deployment-test-always-a-good-idea">For a Local Deployment test (always a good idea)</h3>

<ol>
  <li>Set up the local Environment in Azure and switch to it</li>
  <li>Register a model (the ML model, e.g. a saved CNTK model in a <a href="https://en.wikipedia.org/wiki/Protocol_Buffers">Protobuf</a> based format)</li>
  <li>Create a manifest for all requirements to build an image (e.g. model, dependencies and can include multiple models)</li>
  <li>Create a docker image with the environment and pertinent files</li>
  <li>Create and deploy the service using the docker image</li>
</ol>

<h3 id="for-the-remote-cluster-deployment">For the Remote Cluster deployment</h3>

<ol>
  <li>Set up the remote cluster Environment in Azure and switch to it</li>
  <li>Create and deploy the service with the same image as from local deployment</li>
</ol>

<h2 id="the-command-sequence">The Command Sequence</h2>

<p>After creating the scoring file, <code class="highlighter-rouge">score.py</code> here, and placing all necessary package installs into a <code class="highlighter-rouge">requirements.txt</code> file (for a Python package manager to use) we can begin our deployment.</p>

<h3 id="deploy-locally-to-test">Deploy locally to test</h3>

<p>For most of the commands as reference see this <a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-service-deploy#4-register-a-model">Doc</a>, however some more specific instructions are here that may be useful for a specialized framework model as can be made with CNTK or TensorFlow, for example.  Other commands around setup are found in this <a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/deployment-setup-configuration">Doc</a>.</p>

<p>These commands can be run in a Jupyter notebook, hence the bang, “!”, preceding the command.  If these are run on the command line please remove the “!”.</p>

<blockquote>
  <p>TIP:  If on the Data Science Virtual Machine which has this CLI, you may need to run these commands a little differently (replace <code class="highlighter-rouge">az</code> with <code class="highlighter-rouge">{sys.executable} -m azure.cli</code>).  e.g. in a Jupyter code cell:</p>
  <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Get Azure ML CLI help on DSVM
import sys
! {sys.executable} -m azure.cli ml -h
</code></pre></div>  </div>
</blockquote>

<p><strong>Log into Azure</strong></p>

<p>Simply:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># This will send a code to prompt for password through the browser</span>
<span class="o">!</span> az login
</code></pre></div></div>

<p>Or if you’ve created a couple of system variables with the username and password:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Using two system variable, the user-defined Azure username and password</span>
<span class="o">!</span> az login <span class="nt">--username</span> <span class="s2">"</span><span class="nv">$AZ_USER</span><span class="s2">"</span> <span class="nt">--password</span> <span class="s2">"</span><span class="nv">$AZ_PASS</span><span class="s2">"</span>
</code></pre></div></div>

<p><strong>Register three Environment Providers</strong></p>

<p>To start the setup process, you need to register a few environment providers by entering the following commands</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span> az provider register <span class="nt">-n</span> Microsoft.MachineLearningCompute
<span class="o">!</span> az provider register <span class="nt">-n</span> Microsoft.ContainerRegistry
<span class="o">!</span> az provider register <span class="nt">-n</span> Microsoft.ContainerService
</code></pre></div></div>

<p><strong>Create a Model Management Account in Azure</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># ! az ml account modelmanagement create -l [Azure region, e.g. eastus2] -n [your account name] -g [resource group name] --sku-instances [number of instances, e.g. 1] --sku-name [Pricing tier for example S1]</span>
<span class="o">!</span> az ml account modelmanagement create <span class="nt">-l</span> westeurope <span class="nt">-n</span> happymodelmgmt <span class="nt">-g</span> happyprojrg <span class="nt">--sku-instances</span> 1 <span class="nt">--sku-name</span> S1
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml account modelmanagement set -n [your account name] -g [resource group it was created in]</span>
<span class="o">!</span> az ml account modelmanagement <span class="nb">set</span> <span class="nt">-n</span> happymodelmgmt <span class="nt">-g</span> happyprojrg
</code></pre></div></div>

<p><strong>Set up the local Environment in Azure and switch to it</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml env setup -l [Azure Region, e.g. eastus2] -n [your environment name] [-g [existing resource group]]</span>
<span class="o">!</span> <span class="nb">printf</span> <span class="s1">'y'</span> | az ml <span class="nb">env </span>setup <span class="nt">-l</span> <span class="s2">"West Europe"</span> <span class="nt">-n</span> localenv <span class="nt">-g</span> happyprojrg
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml env show -n [environment name] -g [resource group]</span>
<span class="o">!</span> az ml <span class="nb">env </span>show <span class="nt">-n</span> localenv <span class="nt">-g</span> happyprojrg
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml env set -n [environment name] -g [resource group]</span>
<span class="o">!</span> az ml <span class="nb">env set</span> <span class="nt">-n</span> localenv <span class="nt">-g</span> happyprojrg
</code></pre></div></div>

<p><strong>Register a model  (the ML model, e.g. a saved CNTK model in a <a href="https://en.wikipedia.org/wiki/Protocol_Buffers">Protobuf</a> based format)</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Get help on this</span>
<span class="o">!</span> az ml model register <span class="nt">--help</span>
</code></pre></div></div>

<p>This will output the model ID:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml model register --model [path to model file] --name [model name]</span>
<span class="o">!</span> az ml model register <span class="nt">--model</span> happy_classifier_cntk.model <span class="nt">--name</span> happy_classifier_cntk.registered.model
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Show the registered models</span>
<span class="o">!</span> az ml model list <span class="nt">-o</span> table
</code></pre></div></div>

<p><strong>Create a manifest for all requirements to build an image</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Get help on this</span>
<span class="o">!</span> az ml manifest create <span class="nt">--help</span>
</code></pre></div></div>

<p>After having the requirements file (user generated list of <code class="highlighter-rouge">pip</code> installable packages needed) and the service schema file (representing the json payload for the service call which is created by running the <code class="highlighter-rouge">main</code> method in <code class="highlighter-rouge">score.py</code> mentioned above, e.g., <code class="highlighter-rouge">python score.py</code>), one can create the manifest to hold this information along with other requirements.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml manifest create --manifest-name [your new manifest name] --model-id [model id] -f [path to code file] -r [runtime for the image, e.g. spark-py] -p [pip installs, e.g. requirements.txt] -d [extra files, e.g. a label file] -s [service schema. e.g. service_schema.json] --verbose --debug</span>
<span class="c"># Note must have requirements file and manifest name mustn't have underscores but rather '.' or '-'</span>
<span class="o">!</span> az ml manifest create <span class="nt">--manifest-name</span> happyclassifiermanifest <span class="nt">--model-id</span> <span class="o">[</span>model <span class="nb">id </span>from register <span class="nb">command</span><span class="o">]</span> <span class="nt">-r</span> python <span class="nt">-p</span> requirements.txt <span class="nt">-d</span> target_set.txt <span class="nt">-f</span> score.py <span class="nt">-s</span> service_schema.json <span class="c">#--verbose --debug</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span> az ml manifest show <span class="nt">-i</span> <span class="o">[</span>manifest <span class="nb">id</span><span class="o">]</span>
</code></pre></div></div>

<p><strong>Create a docker image with the environment and pertinent files</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Ensure correct permissions for docker and add user to docker group</span>
<span class="o">!</span> <span class="nb">sudo chmod</span> <span class="nt">-R</span> ugo+rwx /var/run/
<span class="o">!</span> <span class="nb">sudo </span>usermod <span class="nt">-aG</span> docker <span class="o">[</span>your current user]
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Get help on this</span>
<span class="o">!</span> az ml image create <span class="nt">--help</span>
</code></pre></div></div>

<p>This will produce an image ID:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml image create -n [image name] --manifest-id [the manifest ID]</span>
<span class="o">!</span> az ml image create <span class="nt">-n</span> happyclassifierimage <span class="nt">--manifest-id</span> <span class="o">[</span>manifest <span class="nb">id</span><span class="o">]</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Get the usage in order to pull the image</span>
<span class="o">!</span> az ml image usage <span class="nt">-i</span> <span class="o">[</span>image <span class="nb">id</span><span class="o">]</span>
</code></pre></div></div>

<p><strong>(Optional) Test the docker image</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># To log in as a docker user</span>
<span class="o">!</span> az ml <span class="nb">env </span>get-credentials <span class="nt">-g</span> happyprojrg <span class="nt">-n</span> localenv
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Log in to docker and pull down image from ACR, then run</span>
<span class="o">!</span> docker login <span class="nt">-u</span> <span class="o">[</span>username] <span class="nt">-p</span> <span class="o">[</span>password] <span class="o">[</span>loginServer]
<span class="o">!</span> docker pull <span class="o">[</span>image name from usage <span class="nb">command</span><span class="o">]</span>
<span class="o">!</span> docker run <span class="o">[</span>image name from usage <span class="nb">command</span><span class="o">]</span>
</code></pre></div></div>

<p><strong>Create and deploy the service using the docker image</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml service create realtime --image-id [image id] -n [service name]</span>
<span class="o">!</span> <span class="nb">printf</span> <span class="s1">'y'</span> | az ml service create realtime <span class="nt">--image-id</span> <span class="o">[</span>image <span class="nb">id</span><span class="o">]</span> <span class="nt">-n</span> localhappywebservice
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Get logs from creation in case something went wrong</span>
<span class="o">!</span> az ml service logs realtime <span class="nt">-i</span> localhappywebservice
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml service usage realtime -i [service id]</span>
<span class="o">!</span> az ml service usage realtime <span class="nt">-i</span> localhappywebservice
</code></pre></div></div>

<p><strong>Test it</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml service run realtime -i &lt;service id&gt; -d "{\"input_df\": [{\"sepal length\": 3.0, \"sepal width\": 3.6, \"petal width\": 1.3, \"petal length\":0.25}]}"</span>
<span class="c"># Note the removal in the json payload of the "u" or unicode designation from docs</span>
<span class="o">!</span> az ml service run realtime <span class="nt">-i</span> localhappywebservice <span class="nt">-d</span> <span class="s2">"{</span><span class="se">\"</span><span class="s2">request_package</span><span class="se">\"</span><span class="s2">: {</span><span class="se">\"</span><span class="s2">url</span><span class="se">\"</span><span class="s2">: </span><span class="se">\"</span><span class="s2">https://contents.mediadecathlon.com/p350121/2000x2000/sq/mountaineering_boots_-_blue_standard_sizes41_42_43_44_45_46_simond_8324356_350121.jpg?k=362304aaf6fecd4b2c8750987a2fb104</span><span class="se">\"</span><span class="s2">}}"</span>
</code></pre></div></div>

<h3 id="deploy-to-a-cluster">Deploy to a cluster</h3>

<p>Follow this <a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/deployment-setup-configuration#cluster-deployment">Doc</a> for more information on cluster deployment.  Below are the pertinent commands working at of 2018-03-11.</p>

<p><strong>Set up the remote cluster Environment in Azure and switch to it</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># az ml env setup --cluster -n [your environment name] -l [Azure region e.g. eastus2] [-g [resource group]]</span>
<span class="o">!</span> <span class="nb">printf</span> <span class="s1">'n\nY'</span> | az ml <span class="nb">env </span>setup <span class="nt">--cluster</span> <span class="nt">-n</span> clusterenv <span class="nt">-l</span> westeurope <span class="nt">-g</span> happyprojrg
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Is the environment ready?</span>
<span class="o">!</span> az ml <span class="nb">env </span>show <span class="nt">-g</span> happyprojrg <span class="nt">-n</span> clusterenv
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Set the environment to the remote cluster</span>
<span class="o">!</span> az ml <span class="nb">env set</span> <span class="nt">-g</span> happyprojrg <span class="nt">-n</span> clusterenv
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Set to same model management account as local</span>
<span class="o">!</span> az ml account modelmanagement <span class="nb">set</span> <span class="nt">-n</span> happymodelmgmt <span class="nt">-g</span> happyprojrg
</code></pre></div></div>

<p><strong>Create and deploy the service with the same image as from local deployment</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># One command to do it all from "scratch"</span>
<span class="c"># ! az ml service create realtime --model-file happy_classifier_cntk.model -f score.py -n remotehappywebservice -s service_schema.json -r python -p requirements.txt -d target_set.txt --verbose --debug</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Remotely deployed kubernetes cluster for predicting and scoring new images with the model </span>
<span class="o">!</span> az ml service create realtime <span class="nt">--image-id</span> <span class="o">[</span>image <span class="nb">id</span><span class="o">]</span> <span class="nt">-n</span> remotehappywebservice
</code></pre></div></div>

<p><strong>Test it</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span> az ml service run realtime <span class="nt">-i</span> <span class="o">[</span>service <span class="nb">id</span><span class="o">]</span> <span class="nt">-d</span> <span class="s2">"{</span><span class="se">\"</span><span class="s2">request_package</span><span class="se">\"</span><span class="s2">: {</span><span class="se">\"</span><span class="s2">url</span><span class="se">\"</span><span class="s2">: </span><span class="se">\"</span><span class="s2">https://contents.mediadecathlon.com/p350121/2000x2000/sq/mountaineering_boots_-_blue_standard_sizes41_42_43_44_45_46_simond_8324356_350121.jpg?k=362304aaf6fecd4b2c8750987a2fb104</span><span class="se">\"</span><span class="s2">}}"</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Even though successful, might still take some time to deprovision everything in Azure</span>
<span class="o">!</span> az ml service delete realtime <span class="nt">--id</span> <span class="o">[</span>service <span class="nb">id</span><span class="o">]</span>
</code></pre></div></div>

<p>Finis!</p>

<h2 id="references">References</h2>

<p><strong>Important Notes</strong></p>

<ul>
  <li>There are different input data type options for sending up to the service and you can specify this when you generate the schema for the service call.</li>
  <li>Install the Azure ML CLI into the system Python if using a DSVM and the main Python in a local setup with (from this <a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/deployment-setup-configuration#using-the-cli">Doc</a>):
  <code class="highlighter-rouge">! sudo pip install -r https://aka.ms/az-ml-o16n-cli-requirements-file</code></li>
  <li>When creating the image with the <code class="highlighter-rouge">az ml</code> cli, remember to include all files necessary with the <code class="highlighter-rouge">-d</code> flag such as any label or data files.  Avoid using the <code class="highlighter-rouge">-c</code> flag for the conda dependencies file for the time being.  If particluar installs are needed, a <code class="highlighter-rouge">requirements.txt</code> file can be used with the <code class="highlighter-rouge">pip</code> installable packages specified and this files should go after a<code class="highlighter-rouge">-p</code> flag.</li>
</ul>

<p><strong>Overview</strong></p>

<ul>
  <li>Overview of Azure ML model management <a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-overview" target="_blank">Doc</a></li>
  <li>Deployment walkthrough <a href="https://azure.github.io/LearnAI-Bootcamp/lab04.2-deploying_a_scoring_service_to_aks/0_README" target="_blank">Ref</a></li>
</ul>

<p><strong>More on Deployment</strong></p>

<ul>
  <li>Microsoft Blog on deploying from Azure ML Workbench and the Azure ML CLI <a href="https://blogs.technet.microsoft.com/machinelearning/2017/09/25/deploying-machine-learning-models-using-azure-machine-learning/" target="_blank">Ref</a></li>
  <li>Setting up with the Azure ML CLI for deployment 
<a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/deployment-setup-configuration" target="_blank">Doc</a></li>
  <li>Non-CLI deployment methods (AML alternative) <a href="https://github.com/Azure/ACS-Deployment-Tutorial" target="_blank">Ref</a></li>
</ul>

<p><strong>Scoring File and Schema Creation References</strong></p>

<ul>
  <li>Example of schema generation <a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-service-deploy#2-create-a-schemajson-file" target="_blank">Doc</a></li>
  <li>Example of the scoring file showing a CNTK model and serializing an image as a <code class="highlighter-rouge">PANDAS</code> data type for input data to service <a href="https://github.com/Azure/MachineLearningSamples-ImageClassificationUsingCntk/blob/master/scripts/deploymain.py" target="_blank">Ref</a></li>
  <li>Example of the scoring file showing a <code class="highlighter-rouge">scikit-learn</code> model and a <code class="highlighter-rouge">STANDARD</code> data type (json) for input data to service <a href="https://github.com/Azure/Machine-Learning-Operationalization/blob/master/samples/python/code/newsgroup/score.py" target="_blank">Ref</a></li>
  <li>After creating a <code class="highlighter-rouge">run</code> and <code class="highlighter-rouge">init</code> methods as in the links above, plus a schema file, begin with “Register a model” found in this <a href="https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-service-deploy#4-register-a-model">Doc</a></li>
  <li>Sample code from Azure on GitHub:  <a href="https://github.com/Azure?utf8=%E2%9C%93&amp;q=MachineLearningSamples&amp;type=&amp;language=">Ref</a></li>
</ul>

<p><strong>Docker</strong></p>

<ul>
  <li>Docker Docs <a href="https://docs.docker.com/get-started/" target="_blank">Ref</a></li>
</ul>

