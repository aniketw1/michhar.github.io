<p><strong>tl;dr</strong>:  MLflow is already powerful, yet simple, even in alpha release.  It’ integration with platforms for training and deployment, such as with AzureML, is incredibly helpful.  After all, don’t we all want to deploy eventually?</p>

<p><strong>Posted:</strong>  2019-09-15</p>

<h2 id="introduction-to-mlflow">Introduction to MLFlow</h2>

<p>Recently, I discovered MLflow on a hunt for a way to track my models and environment, parameters, training and deployments (that was a nice addition) in a single project and a single place.</p>

<p>A few features that caught my eye:</p>

<ul>
  <li>Run training and deployment from a remote GitHub repo</li>
  <li>Log the environment in which a model was trained (other logging and even a UI for tracking)</li>
  <li>Many deployment options (local and Azure ML among others)</li>
</ul>

<p>After trying MLflow, I discovered that I liked:</p>

<ul>
  <li>The flexibility of running the project in several locations (local, <a href="https://databricks.com/">Databricks</a>, remote linux VMs, etc.)</li>
  <li>Error messaging is clear and includes a nice stacktrace</li>
  <li>The deployment was straighforward as the project for AzureML was generated for me with the files I needed</li>
</ul>

<h2 id="get-the-model-and-data">Get the Model and Data</h2>

<p>Feel free to follow along or create your own project.  This is an example of using MLFlow with an existing repo.</p>

<ol>
  <li>Clone the YOLOv3 Keras example repo:</li>
</ol>

<blockquote>
  <p><code class="highlighter-rouge">git clone https://github.com/michhar/mlflow-keras-example.git</code></p>
</blockquote>

<ol>
  <li>cd into model directory:</li>
</ol>

<blockquote>
  <p><code class="highlighter-rouge">cd mlflow-keras-example/model_data/</code></p>
</blockquote>

<ol>
  <li>Download the model, data (or create your own) and pointer file to data.
    <ul>
      <li>
        <p>Get a Keras-friendly YOLOv3 base model, converted directly from the Tiny YOLOv3 Darknet model (here, the Tiny weights are used - nice for constrained devices):</p>

        <blockquote>
          <p>Click to access through Azure Storage <a href="https://modelsdata.blob.core.windows.net/data/yolov3-tiny.h5">here (34MB)</a>, download and place model in <code class="highlighter-rouge">model_data</code> subdirectory</p>
        </blockquote>
      </li>
      <li>
        <p>Get some sample data of lego minifigures with helmets and other head gear to train a model to detect what the figurine is wearing on its head, placing the uznipped folder in the <code class="highlighter-rouge">voc</code> subdirectory.</p>

        <blockquote>
          <p>Click to access through from <a href="https://modelsdata.blob.core.windows.net/data/JPEGImages.zip">here (173MB)</a> or use your own data (according to instructions on this repo <a href="https://github.com/michhar/keras-yolo3#training">in Step 1</a> - you’ll need to label as well).</p>
        </blockquote>
      </li>
      <li>
        <p>Get the list of images as a small text file with associated bounding boxes and class.</p>

        <blockquote>
          <p>Click to access from <a href="https://modelsdata.blob.core.windows.net/data/list_master.txt">here</a> and place it in the <code class="highlighter-rouge">voc</code> subdirectory</p>
        </blockquote>
      </li>
    </ul>
  </li>
</ol>

<h2 id="setup-for-mlflow">Setup for MLflow</h2>

<p>Required Python packages:</p>
<ul>
  <li><code class="highlighter-rouge">mlflow</code></li>
  <li><code class="highlighter-rouge">azure-cli</code> (if deploying with AzureML)
    <ul>
      <li>To deploy with <code class="highlighter-rouge">azureml</code> one will need, also, an Azure Subscription.</li>
    </ul>
  </li>
</ul>

<p><code class="highlighter-rouge">MLproject</code> file is an excellent source of control over things.  Optional, but recommended for the following reasons:</p>
<ul>
  <li>Points to conda dependencies file for building this environment before training</li>
  <li>Parameters, types and defaults</li>
  <li>Entrypoint command (with all options) - this is the master command that is run when the mlflow training is run on the command line</li>
</ul>

<p>A simplified <code class="highlighter-rouge">MLproject</code> file is as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>name: My Awesome Project

conda_env: smart_conda.yaml

entry_points:
  main:
    parameters:
      parameter1: {type: str, default: "voc/list_master.txt"}
      parameter2: {type: float, default: 1e-2}
      parameter3: {type: int, default: 16}
    command: "python train.py --parameter1 {parameter1} --parameter2 {parameter2} --parameter3 {parameter3}"
</code></pre></div></div>

<p>If there are defaults, none of these parameters need to exist on the command line when running with <code class="highlighter-rouge">mlflow</code>, however they may be overridden.</p>

<h2 id="training">Training</h2>

<p>To train, all you should need to do from within the cloned repo folder is (runs with default parameters in MLproject entrypoint command):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlfow run .
</code></pre></div></div>

<p>Or if you want to modify a default parameter or two (use <code class="highlighter-rouge">-P</code> per parameter) like the number of epochs for the transfer learning stage (<code class="highlighter-rouge">frozen_epochs</code>) and network fine tuning stage (<code class="highlighter-rouge">fine_tune_epochs</code>) (note you’d use 100s to 1000s of epochs for these in the real world):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlflow run . -P frozen_epochs=5 -P fine_tune_epochs=3
</code></pre></div></div>

<p>Also, you can monitor the run through <code class="highlighter-rouge">tensorboard</code> which is part of a callback in the <code class="highlighter-rouge">model.fit</code> method (change logdir as appropriate).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensorboard --logdir logs/default
</code></pre></div></div>

<p>An <code class="highlighter-rouge">mlflow</code> option for monitoring is with:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlflow ui
</code></pre></div></div>

<p>The metric and model (as an artifact) is recorded by the following:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Added for MLflow
</span><span class="n">mlflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">"keras-yolo-model-frozen-pass"</span><span class="p">)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s">'frozen_loss'</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div></div>

<p>What does <code class="highlighter-rouge">mlflow run</code> actually do?  As follows:</p>

<ul>
  <li>Creates the conda environment based on the <code class="highlighter-rouge">yolo_conda.yml</code> file (or whatever you named the dependencies file)</li>
  <li>Runs the entrypoint script described in the <code class="highlighter-rouge">MLproject</code> file (this file is not mandatory, but makes customizing the training process much easier).</li>
  <li>Logs any artifacts specified in <code class="highlighter-rouge">train.py</code> (e.g. save model as an asset with <code class="highlighter-rouge">mlflow.keras.log_model(model, "keras-yolo-model-frozen-pass")</code>)</li>
  <li>Logs any metrics specified in <code class="highlighter-rouge">train.py</code> (e.g. log loss with <code class="highlighter-rouge">mlflow.log_metric('finetune_loss', model.loss)</code>)</li>
</ul>

<h3 id="artifacts">Artifacts</h3>

<p>If model is logged as in this training script, a folder should appear in the <code class="highlighter-rouge">mlflow</code> UI with information on the training run and the model itself.</p>

<p>To find the model, look in the <code class="highlighter-rouge">mlruns</code> directory at the base of the project:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ls mlruns/0/&lt;run id given at end of successful run&gt;/artifacts/&lt;model key from train.py&gt;
</code></pre></div></div>

<p>E.g. For the final model after fine-tuning:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ls mlruns/0/8237d734f1d94fd893368dd455565f2d/artifacts/keras-yolo-model
</code></pre></div></div>

<p>It will be called something like <code class="highlighter-rouge">model.h5</code>.</p>

<h2 id="deploying-with-the-azure-machine-learning-integration">Deploying with the Azure Machine Learning Integration</h2>

<p>Now, to get the package for the AzureML deployment CLI:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install -r https://aka.ms/az-ml-o16n-cli-requirements-file
</code></pre></div></div>

<p>(Corresponding to <code class="highlighter-rouge">azure-cli-ml==0.1.0a27.post3</code> at the time of writing).</p>

<p>See <a href="https://mlflow.org/docs/latest/models.html#microsoft-azureml">AzureML export option and CLI commands from mlflow</a> for the detailed directions.</p>

<p>For instance, to export to <code class="highlighter-rouge">azureml</code>-friendly deployment format/structure (and create neccessary files for this deployment type) the command will have the format:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlflow azureml export -m mlruns/&lt;run folder&gt;/&lt;run id&gt;/artifacts/&lt;name of mlflow project&gt; -o &lt;name of new folder for azureml&gt;
</code></pre></div></div>

<p>E.g.:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlflow azureml export -m mlruns/0/8237d734f1d94fd893368dd455565f2d/artifacts/keras-yolo-model -o yolo-output
</code></pre></div></div>

<p>Note, some additional libraries may need to be specified in the generated <code class="highlighter-rouge">score.py</code>’s <code class="highlighter-rouge">init()</code> and <code class="highlighter-rouge">run()</code>, such as <code class="highlighter-rouge">keras</code> here:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">init</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">model</span>
    <span class="kn">import</span> <span class="nn">keras</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">load_pyfunc</span><span class="p">(</span><span class="s">"model"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">keras</span>
    <span class="n">input_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s">"records"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">get_jsonable_obj</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_df</span><span class="p">))</span>
</code></pre></div></div>

<blockquote>
  <p>Note: not including necessary packages is the most common source of error in deploying with AzureML</p>
</blockquote>

<p>Ensure <code class="highlighter-rouge">yolo-output</code> (or name used for <code class="highlighter-rouge">mlflow</code> generated file directory) has all necessary packages beyond <code class="highlighter-rouge">mlflow</code>, namely:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>numpy==1.14.2
matplotlib==2.2.2
Keras==2.2.2
tensorflow==1.8.0
Pillow==5.1.0
mlflow==0.5.2
</code></pre></div></div>

<p>The <code class="highlighter-rouge">azureml</code> CLI commands are:</p>

<blockquote>
  <p>Note: one may need to register some environment providers in Azure.
<code class="highlighter-rouge">az provider register -n Microsoft.MachineLearningCompute</code>
<code class="highlighter-rouge">az provider register -n Microsoft.ContainerRegistry</code>
<code class="highlighter-rouge">az provider register -n Microsoft.ContainerService</code></p>
</blockquote>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az login

az ml env setup -l [Azure Region, e.g. eastus2] -n [your environment name] [-g [existing resource group]]

az ml env set -n [environment name] -g [resource group]

mlflow azureml deploy &lt;parameters&gt;
</code></pre></div></div>

<p>See AzureML documentation for more information on the <code class="highlighter-rouge">az ml</code> commands for deployment or type <code class="highlighter-rouge">az ml -h</code>.</p>

<p>Use a model management account (or create one).  List them with:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az ml account modelmanagement list
</code></pre></div></div>

<p>Set one with:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az ml account modelmanagement set -g [resource group] -n [model management name]
</code></pre></div></div>

<p><strong>For example, the commands used in this project to deploy locally are as follows</strong></p>

<p>Log in to Azure:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az login
</code></pre></div></div>

<p>Set up an environment:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az ml env setup -l eastus2 -g localyoloenvrg -n localyoloenv
</code></pre></div></div>

<ul>
  <li>This will take a few minutes.</li>
</ul>

<p>Choose the environment:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az ml env set -g localyoloenvrg -n localyoloenv
</code></pre></div></div>

<p>Deploy the project, now (locally, but linked to a few resources online):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlflow azureml deploy --model-path model -n yoloapp123
</code></pre></div></div>

<p>When done, clean up by deleting the resource group with:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az group delete -g localyoloenvrg
</code></pre></div></div>

<h2 id="setting-up-mlflow-on-databricks">Setting up MLflow on Databricks</h2>

<p>Recommendations.<br />
Set this up and begin with a PyTorch tutorial with Mlflow server to ensure all is well before moving on to code.</p>

<p>Note:  Make sure the versions of packages on Databricks matches the versions of packages on the Linux VM hosting the Mlflow tracking server.</p>

<ol>
  <li>Provision Databricks workspace on Azure - Premium tier in WestUS2 (Premium tier for access control so we can manage users)</li>
  <li>
    <p>Provision a small, general-purpose Linux VM (Ubuntu 16.04 Server is good) for an ML tracking server to let us monitor, log and save artifacts from training experiments on Databricks:</p>

    <ul>
      <li>Use Password for authentication</li>
      <li>Open up traffic to 80 (HTTP) and 22 (SSH)</li>
    </ul>
  </li>
  <li>Provision a new Storage Account or create a container for mlflow artifacts in an existing blob Storage Account.</li>
  <li>Follow directions for setting up the Mlflow tracking server on this new Linux VM at https://docs.azuredatabricks.net/spark/latest/mllib/mlflow.html#mlflow-mlflow-quick-start-notebook under “Set up a Remote MLflow Tracking Server”
    <ul>
      <li>Use “python3” and “pip3”</li>
      <li>To get requirements installed (namely <code class="highlighter-rouge">azure-storage</code>), must first run from the VM:</li>
    </ul>

    <p><code class="highlighter-rouge">sudo apt-get install python3-pip python3-dev libffi-dev libssl-dev libxml2-dev libxslt1-dev libjpeg8-dev zlib1g-dev</code></p>

    <ul>
      <li>Need to install “flask” to get this server working right:   pip3 install flask</li>
      <li>Add inbound rule for port 5000 to the network security gateway for this VM (should be in the same resource group as VM) - docs for this at https://docs.microsoft.com/en-us/azure/virtual-machines/windows/nsg-quickstart-portal, but just note, an NSG already exists, so just add the rule there</li>
      <li>When starting the server make sure to start it in background with “&amp;” - it should then be at  your <code class="highlighter-rouge">http://dnsname:5000</code></li>
    </ul>
  </li>
  <li>Set up for PyTorch and MLFlow by following this tutorial (instructions on Cluster set up there - do GPU with runtime 4.3): https://docs.azuredatabricks.net/_static/notebooks/mlflow/mlflow-pytorch-azure.html
    <ul>
      <li>Make sure to set the Azure blob storage connection string in Databricks before trying Mlflow server tracking (see https://docs.azuredatabricks.net/spark/latest/mllib/mlflow.html#mlflow-mlflow-quick-start-notebook)</li>
      <li>If encountering trouble with cluster deployment, try Worker as NC12 and driver as NC12 type VM and ensure you have the proper quotas</li>
    </ul>
  </li>
</ol>

<p>Set these in something like “.azurerc” and source it before launching the tracking server:</p>

<p>AZURE_STORAGE_ACCESS_KEY=&lt;keypart==&gt;
AZURE_STORAGE_CONNECTION_STRING=”DefaultEndpointsProtocol=https;AccountName=whatsinaname;AccountKey=lotsofalphanumericsymbols==;EndpointSuffix=core.windows.net”</p>

<h2 id="example">Example</h2>

<p>See an example MLflow project at https://github.com/michhar/mlflow-keras-example.</p>

<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    
    var disqus_config = function () {
        this.page.url = 'https://michhar.github.io/setting-up-for-and-work-with-mlflow/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'happycat1'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        
        s.src = 'https://michhar.disqus.com/embed.js';
        
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
