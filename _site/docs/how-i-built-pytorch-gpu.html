<p><img src="img/my_desk_building_pytorch.jpg" alt="" /></p>

<p><strong>tl;dr</strong>:  Notes on building PyTorch 1.0 Preview and other versions from source including LibTorch, the PyTorch C++ API for fast inference with a strongly typed, compiled language.  So fast.</p>

<p><strong>Posted:</strong>  2018-11-10</p>

<h2 id="introduction">Introduction</h2>

<p>I’d like to share some notes on building PyTorch from source from various releases using commit ids.  This process allows you to build from any commit id, so you are not limited to a release number only.</p>

<p>I’ve used this to build PyTorch with LibTorch for Linux amd64 with an NVIDIA GPU and Linux aarch64 (e.g. NVIDIA Jetson TX2).</p>

<h2 id="instructions">Instructions</h2>

<p>Create a shell script with the following contents (this being only an example) and refer to rest of post for possible changes you may have to make.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Post 1.0rc1 for a few fixes I needed</span>
<span class="nv">PYTORCH_COMMIT_ID</span><span class="o">=</span><span class="s2">"8619230"</span>

<span class="c"># Clone, checkout specific commit and build for GPU with CUDA support</span>
git clone https://github.com/pytorch/pytorch.git <span class="o">&amp;&amp;</span><span class="se">\</span>
    <span class="nb">cd </span>pytorch <span class="o">&amp;&amp;</span> git checkout <span class="k">${</span><span class="nv">PYTORCH_COMMIT_ID</span><span class="k">}</span> <span class="o">&amp;&amp;</span> <span class="se">\</span>
    git submodule update <span class="nt">--init</span> <span class="nt">--recursive</span>  <span class="o">&amp;&amp;</span><span class="se">\</span>
    pip3 <span class="nb">install </span><span class="nv">pyyaml</span><span class="o">==</span>3.13 <span class="o">&amp;&amp;</span><span class="se">\</span>
    pip3 <span class="nb">install</span> <span class="nt">-r</span> requirements.txt <span class="o">&amp;&amp;</span><span class="se">\</span>
    <span class="nv">USE_OPENCV</span><span class="o">=</span>1 <span class="se">\</span>
    <span class="nv">BUILD_TORCH</span><span class="o">=</span>ON <span class="se">\</span>
    <span class="nv">CMAKE_PREFIX_PATH</span><span class="o">=</span><span class="s2">"/usr/bin/"</span> <span class="se">\</span>
    <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/usr/local/cuda/lib64:/usr/local/lib:<span class="nv">$LD_LIBRARY_PATH</span> <span class="se">\</span>
    <span class="nv">CUDA_BIN_PATH</span><span class="o">=</span>/usr/local/cuda/bin <span class="se">\</span>
    <span class="nv">CUDA_TOOLKIT_ROOT_DIR</span><span class="o">=</span>/usr/local/cuda/ <span class="se">\</span>
    <span class="nv">CUDNN_LIB_DIR</span><span class="o">=</span>/usr/local/cuda/lib64 <span class="se">\</span>
    <span class="nv">CUDA_HOST_COMPILER</span><span class="o">=</span>cc <span class="se">\</span>
    <span class="nv">USE_CUDA</span><span class="o">=</span>1 <span class="se">\</span>
    <span class="nv">USE_NNPACK</span><span class="o">=</span>1 <span class="se">\</span>
    <span class="nv">CC</span><span class="o">=</span>cc <span class="se">\</span>
    <span class="nv">CXX</span><span class="o">=</span>c++ <span class="se">\</span>
    <span class="nv">TORCH_CUDA_ARCH_LIST</span><span class="o">=</span><span class="s2">"3.5 5.2 6.0 6.1+PTX"</span> <span class="se">\</span>
    <span class="nv">TORCH_NVCC_FLAGS</span><span class="o">=</span><span class="s2">"-Xfatbin -compress-all"</span> <span class="se">\</span>
    python3 setup.py bdist_wheel

<span class="c"># Install the Python wheel (includes LibTorch)</span>
pip3 <span class="nb">install </span>dist/<span class="k">*</span>.whl

<span class="c"># Clean up resources</span>
<span class="nb">rm</span> <span class="nt">-fr</span> pytorch
</code></pre></div></div>

<ul>
  <li>Note, the size of the binary/wheel can be up to 180 MB.</li>
</ul>

<h3 id="build-flag-meanings">Build flag meanings</h3>

<ul>
  <li>USE_OPENCV=1 - build with OpenCV support</li>
  <li>BUILD_TORCH=ON - build LibTorch (C++ API)</li>
  <li>CMAKE_PREFIX_PATH=”/usr/bin/” - where to find Python</li>
  <li>LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/lib:$LD_LIBRARY_PATH - build lib paths</li>
  <li>CUDA_BIN_PATH=/usr/local/cuda/bin - where to find current CUDA</li>
  <li>CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/ - where to find current CUDA Toolkit</li>
  <li>CUDNN_LIB_DIR=/usr/local/cuda/lib64 - where to find cuDNN install</li>
  <li>CUDA_HOST_COMPILER=cc - sets the host compiler to be used by nvcc</li>
  <li>USE_CUDA=1 - compile with CUDA support</li>
  <li>USE_NNPACK=1 - compile with cuDNN</li>
  <li>CC=cc - which C compiler to use for PyTorch build</li>
  <li>CXX=c++ - which C++ compiler to use for PyTorch build</li>
  <li>TORCH_CUDA_ARCH_LIST=”3.5 5.2 6.0 6.1+PTX” - GPU architectures to accomodate</li>
  <li>TORCH_NVCC_FLAGS=”-Xfatbin -compress-all” - extra <code class="highlighter-rouge">nvcc</code> (NVIDIA CUDA compiler driver) flags</li>
</ul>

<h3 id="changes-to-script-that-may-be-necessary">Changes to script that may be necessary</h3>

<ul>
  <li>Update <code class="highlighter-rouge">pip3</code> to <code class="highlighter-rouge">pip</code> as necessary (However, it’s recommended to build with Python 3 system installs)</li>
  <li>Update <code class="highlighter-rouge">CMAKE_PREFIX_PATH</code> to your <code class="highlighter-rouge">bin</code> where Python lives</li>
  <li>Update <code class="highlighter-rouge">PYTORCH_COMMIT_ID</code> to one you wish to use.  Official release commit ids are
    <ul>
      <li>v0.3.1 - <code class="highlighter-rouge">2b47480</code> (which I still needed for a project)</li>
      <li>v0.4.0 - <code class="highlighter-rouge">3749c58</code></li>
      <li>v0.4.1 - <code class="highlighter-rouge">a24163a</code></li>
      <li>v1.0rc1 - <code class="highlighter-rouge">ff608a9</code></li>
    </ul>
  </li>
  <li>If compiling on macOS, update to the following:
    <ul>
      <li>CC=clang</li>
      <li>CXX=clang++</li>
      <li>CUDA_HOST_COMPILER=clang</li>
    </ul>
  </li>
  <li>To compile without CUDA support (e.g. on CPU-only), update to the following:
    <ul>
      <li>USE_CUDA=0</li>
      <li>USE_NNPACK=0</li>
    </ul>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Given the right hardware (Linux amd64 or even aarch64 like a TX2) - the above script will work to build PyTorch and LibTorch.  Leave a comment if you wish - issues or suggestions welcome.</p>

<h2 id="references">References</h2>

<ol>
  <li><a href="https://pytorch.org/get-started/locally/#mac-from-source">PyTorch official build instructions</a></li>
  <li><a href="https://github.com/pytorch/pytorch/blob/master/docker/pytorch/Dockerfile">PyTorch official Dockerfile</a></li>
  <li><a href="https://github.com/michhar/custom-jupyterhub-linux-vm/blob/master/Linux_py35_GPU.dockerfile#L199">Micheleen’s GPU VM Dockerfile with a PyTorch+LibTorch build included</a></li>
  <li><a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">NVCC from NVIDIA Docs</a></li>
</ol>

<h2 id="thank-yous">Thank Yous</h2>

<p>To PyTorch GitHub Issues with great activity and insights (https://github.com/pytorch/pytorch/issues) and the official PyTorch Forums (https://discuss.pytorch.org/).</p>

<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    
    var disqus_config = function () {
        this.page.url = 'https://michhar.github.io/how-i-built-pytorch-gpu/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'happycat2'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        
        s.src = 'https://michhar.disqus.com/embed.js';
        
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
